# R + LLM Blog Demo

This repository showcases a case study on orchestrating R analytics workflows with locally hosted Large Language Models (LLMs) via Ollama. The blog explores how chaining LLM prompts within R can enhance clarity, depth, and decision-ready insights.

## Contents
- `index.html`: Rendered blog post
- `fig/`: Contains supporting images used in the blog

## Notes
- LLMs are hosted locally via Ollama and accessed over a LAN.
- The blog uses Qwen2.5 for demonstration, but the architecture supports model-switching per prompt.
- Source `.Rmd` and setup instructions will be added in future updates.

 
